{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92cf8e4-700b-4275-9744-a651f2f7c605",
   "metadata": {},
   "source": [
    "# Authors: Barış Bali (20190301510) Computer Engineering (4+1)\n",
    "#          Mustafa Dindar (20180301010) Computer Engineering (4+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2835e2bc-e15d-444c-911b-6cb68c400382",
   "metadata": {},
   "source": [
    "# Titanic Dataset Classification Model\n",
    "1) Selected Dataset in csv format is: Titanic Dataset from Kagle.\n",
    "2) Attributes in detail: \r\n",
    "\r\n",
    "PassengerId: A unique identifier for each passenger.  \r\n",
    "\r\n",
    "Survived: Indicates if the passenger survived (1) or did not survive (0).  \r\n",
    "\r\n",
    "Pclass (Ticket Class): Represents the ticket class (1st, 2nd, or 3rd class).  \r\n",
    "\r\n",
    "Name: Name of the passenger.  \r\n",
    "\r\n",
    "Sex: Gender of the passenger (male or female).  \r\n",
    "\r\n",
    "Age: Age of the passenger (some entries might be missing).  \r\n",
    "\r\n",
    "SibSp: Number of siblings/spouses aboard the Titanic.  \r\n",
    "\r\n",
    "Parch: Number of parents/children aboard the Titanic.  \r\n",
    "\r\n",
    "Ticket: Ticket number.  \r\n",
    "\r\n",
    "Fare: Passenger fare.  \r\n",
    "\r\n",
    "Cabin: Cabin number (some entries might be missing).  \r\n",
    "\r\n",
    "Embarked: Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8765e8f2-4aad-4563-910a-a8e4357f5c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name  Sex   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
      "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
      "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
      "\n",
      "             Ticket     Fare Cabin  Embarked  \n",
      "0         A/5 21171   7.2500   NaN         2  \n",
      "1          PC 17599  71.2833   C85         0  \n",
      "2  STON/O2. 3101282   7.9250   NaN         2  \n",
      "3            113803  53.1000  C123         2  \n",
      "4            373450   8.0500   NaN         2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#3) Convertion the \"Sex\" and \"Embarked\" attribute to numerical values using label encoder.\n",
    "\n",
    "#Reading the data with pandas\n",
    "titanic_df = pd.read_csv('Titanic-Dataset.csv')\n",
    "#displaying dataset read by pandas\n",
    "print(titanic_df.head())\n",
    "\n",
    "label_encoder=LabelEncoder()\n",
    "\n",
    "#Using label encoder to transform this categorical values to numerical values\n",
    "titanic_df['Sex'] = label_encoder.fit_transform(titanic_df['Sex'])\n",
    "titanic_df['Embarked'] = titanic_df['Embarked'].fillna('Unknown') #for filling missing values\n",
    "titanic_df['Embarked'] = label_encoder.fit_transform(titanic_df['Embarked'])\n",
    "\n",
    "#to display with numerical values\n",
    "print(titanic_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f599eb6a-8ca9-4451-922a-51514f76d287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name       Sex       Age  \\\n",
      "0                            Braund, Mr. Owen Harris  0.737695 -0.530377   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th... -1.355574  0.571831   \n",
      "2                             Heikkinen, Miss. Laina -1.355574 -0.254825   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel) -1.355574  0.365167   \n",
      "4                           Allen, Mr. William Henry  0.737695  0.365167   \n",
      "\n",
      "   SibSp  Parch            Ticket      Fare Cabin  Embarked  \n",
      "0      1      0         A/5 21171 -0.502445   NaN  0.581114  \n",
      "1      1      0          PC 17599  0.786845   C85 -1.938460  \n",
      "2      0      0  STON/O2. 3101282 -0.488854   NaN  0.581114  \n",
      "3      1      0            113803  0.420730  C123  0.581114  \n",
      "4      0      0            373450 -0.486337   NaN  0.581114  \n"
     ]
    }
   ],
   "source": [
    "# 4) Normalization using Standart Scaler\n",
    "#normalization with standart scaler module (all numeric values)\n",
    "numeric_columns = ['Age', 'Fare', 'Sex', 'Embarked']\n",
    "scaler =StandardScaler()\n",
    "titanic_df[numeric_columns] = scaler.fit_transform(titanic_df[numeric_columns])\n",
    "#Normalization df\n",
    "print(titanic_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d93041c-56b2-4f74-93c3-38c5fbfbbe9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN (K=3)\n",
      "Accuracy: 0.7430167597765364\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       105\n",
      "           1       0.71      0.64      0.67        74\n",
      "\n",
      "    accuracy                           0.74       179\n",
      "   macro avg       0.74      0.73      0.73       179\n",
      "weighted avg       0.74      0.74      0.74       179\n",
      "\n",
      "KNN (K=7)\n",
      "Accuracy: 0.7541899441340782\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79       105\n",
      "           1       0.71      0.69      0.70        74\n",
      "\n",
      "    accuracy                           0.75       179\n",
      "   macro avg       0.75      0.74      0.75       179\n",
      "weighted avg       0.75      0.75      0.75       179\n",
      "\n",
      "KNN (K=11)\n",
      "Accuracy: 0.7597765363128491\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80       105\n",
      "           1       0.73      0.66      0.70        74\n",
      "\n",
      "    accuracy                           0.76       179\n",
      "   macro avg       0.75      0.75      0.75       179\n",
      "weighted avg       0.76      0.76      0.76       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5) Comparing the performance values.\n",
    "\n",
    "#KNN three time (3,7,10)\n",
    "X = titanic_df[['Age', 'Fare', 'Sex', 'Embarked']] \n",
    "y = titanic_df['Survived'] \n",
    "\n",
    "# Adding a simple imputer because of NaN values in the dataset\n",
    "imputer = SimpleImputer(strategy='mean') \n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "#train test splits for data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "for k in [3, 7, 11]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"KNN (K={k})\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6fedd26-3a51-4319-bee6-19d6054ab454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Development\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP (Config=(32,))\n",
      "Accuracy: 0.7821229050279329\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       105\n",
      "           1       0.75      0.70      0.73        74\n",
      "\n",
      "    accuracy                           0.78       179\n",
      "   macro avg       0.78      0.77      0.77       179\n",
      "weighted avg       0.78      0.78      0.78       179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Development\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP (Config=(32, 32))\n",
      "Accuracy: 0.7486033519553073\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       105\n",
      "           1       0.71      0.66      0.69        74\n",
      "\n",
      "    accuracy                           0.75       179\n",
      "   macro avg       0.74      0.74      0.74       179\n",
      "weighted avg       0.75      0.75      0.75       179\n",
      "\n",
      "MLP (Config=(32, 32, 32))\n",
      "Accuracy: 0.7653631284916201\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80       105\n",
      "           1       0.72      0.72      0.72        74\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.76      0.76      0.76       179\n",
      "weighted avg       0.77      0.77      0.77       179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Development\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#MLP\n",
    "configurations = [\n",
    "    (32,),  # Single hidden layer with 32 neurons\n",
    "    (32, 32),  # Two hidden layers with 32 neurons each\n",
    "    (32, 32, 32),  # Three hidden layers with 32 neurons each\n",
    "]\n",
    "\n",
    "for config in configurations:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=config)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"MLP (Config={config})\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90d2891a-c313-4cec-b2bd-928ed09812c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes\n",
      "Accuracy: 0.7597765363128491\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79       105\n",
      "           1       0.71      0.72      0.71        74\n",
      "\n",
      "    accuracy                           0.76       179\n",
      "   macro avg       0.75      0.75      0.75       179\n",
      "weighted avg       0.76      0.76      0.76       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Naïve Bayes\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a27ec0-8652-4105-8359-d867feac8524",
   "metadata": {},
   "source": [
    "# Analysis results using accuracy P, R adn F values.\n",
    "#  K-Nearest Neighbors (KNN)\r\n",
    "K=3\r\n",
    "Accuracy: 0.743\r\n",
    "Precision: 0.74\r\n",
    "Recall: 0.73\r\n",
    "F1-score: \n",
    "0.74\r\n",
    "K=7\r\n",
    "Accuracy: 0.754\r\n",
    "Precision: 0.75\r\n",
    "Recall: 0.74\r\n",
    "F1-sc\n",
    "ore: 0.75\r\n",
    "K=11\r\n",
    "Accuracy: 0.760\r\n",
    "Precision: 0.75\r\n",
    "Recall: 0.75\r\n",
    "\n",
    "#  F1-score: 0.75\r\n",
    "Multi-Layer Perceptron (MLP)\r\n",
    "Config=(32,)\r\n",
    "Accuracy: 0.777\r\n",
    "Precision: 0.77\r\n",
    "Recall: \n",
    "0.76\r\n",
    "F1-score: 0.77\r\n",
    "Config=(32, 32)\r\n",
    "Accuracy: 0.765\r\n",
    "Precision: 0.76\r\n",
    "Rec\n",
    "all: 0.76\r\n",
    "F1-score: 0.76\r\n",
    "Config=(32, 32, 32)\r\n",
    "Accuracy: 0.754\r\n",
    "Precision: 0.75\n",
    "#  \r\n",
    "Recall: 0.75\r\n",
    "F1-score: 0.75\r\n",
    "Naïve Bayes (NB)\r\n",
    "Accuracy: 0.760\r\n",
    "Precision: 0.75\r\n",
    "Recall: 0.75\r\n",
    "F1-score: 0.75"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
